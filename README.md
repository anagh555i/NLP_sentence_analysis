# NLP Sentence Analysis
A Jupyterâ€Notebook based exploratory project analysing sentences using NLP techniques.

## ğŸ§  Overview
This project performs sentenceâ€level analysis on a given corpus of sentences (see `Sentences.csv`). It uses Python (in Jupyter notebooks) to explore, visualise, and extract insights from the text.  
Itâ€™s ideal for:
- Learning or demonstrating basic NLP workflows (tokenisation, POS, simple statistics).
- Rapid prototyping of sentenceâ€analysis pipelines.
- Educational or proofâ€ofâ€concept usage.

## ğŸ“ Repository Structure
```
/ (root)
â”‚   .gitignore
â”‚   INFO.txt
â”‚   Sentences.csv             â† the main input dataset (sentences)
â”‚   srs.csv                   â† secondary dataset / SRS annotations
â”‚   srsCorpus.csv             â† corpus derived from SRS dataset
â”‚
â”œâ”€â”€ Main.ipynb                â† primary notebook: load data, analyse, visualise
â”œâ”€â”€ TESTING.ipynb             â† notebook for experiments, tests, prototyping
â””â”€â”€ SRS/                      â† folder containing â€œSRSâ€ documentation or assets
    â””â”€â”€ â€¦ 
```

## âœ… Features
- Load a sentence dataset and perform cleaning/preâ€processing.
- Exploratory data analysis (EDA): sentence length distributions, token counts, maybe POS tag counts.
- Visualisations embedded within Jupyter (histograms, bar charts etc).
- Modular notebook design: main pipeline + testing/experimentation notebook.
- Simple, clear structure so newcomers can follow and extend.

## ğŸš€ Getting Started
### Prerequisites
- Pythonâ€¯3.x installed
- Jupyter Notebook (or JupyterLab)
- Common NLP/data libraries (you can install via `pip`):
  ```bash
  pip install pandas numpy matplotlib seaborn nltk spacy
  ```

### Setup
1. Clone the repository:
   ```bash
   git clone https://github.com/anagh555i/NLP_sentence_analysis.git
   cd NLP_sentence_analysis
   ```
2. (Optional) Create a virtual environment:
   ```bash
   python3 -m venv venv
   source venv/bin/activate   # on Windows: venv\Scripts\activate
   ```
3. Install dependencies (see above).
4. Launch Jupyter Notebook:
   ```bash
   jupyter notebook
   ```
   then open `Main.ipynb` and run the cells.

### Usage
- In `Main.ipynb`, cells walk you through: loading the CSV (`Sentences.csv`), inspecting the data, preâ€‘processing (tokenisation, cleaning), generating basic statistics, visualising distributions.
- In `TESTING.ipynb`, you can explore further ideas or test modifications (e.g., different tokenisers, POS tagging, named entities).
- Extend the project by adding new analyses (e.g., sentiment, clustering, topic modelling) or by applying to your own sentence corpus.

## ğŸ“ Customisation & Extending
- Replace `Sentences.csv` with your own dataset of sentences (ensure similar format).
- Add new notebook(s) for advanced NLP tasks (e.g., using the spaCy library, word embeddings, transformer models).
- Modularise code (e.g., move common functions into `.py` modules) for reuse.
- Allow interactive dashboards (e.g., using Streamlit or Dash) on top of the analysis.

## ğŸ” Insights & Findings
*(You can fill this section after youâ€™ve run the analysisâ€”mention interesting patterns you found, e.g., â€œAverage sentence length is 12 wordsâ€, â€œMost common POS tag: nounâ€, etc.)*

## ğŸ“ Use Cases
- Academic/learning: Understand how sentenceâ€level NLP workflows work.
- Prototype for larger projects: Use as a starting point for text analytics.
- Data journalism: Quick snapshot of sentence characteristics in a dataset.

## ğŸ¤ Contributing
If youâ€™d like to contribute:
1. Fork the repo.
2. Create a branch: `git checkout -b feature/yourâ€feature`.
3. Make your changes, test them, commit.
4. Open a Pull Request describing your addition/improvement.
5. Ensure you update this README if you add major functionality.

## ğŸ“œ Licence
*(If you havenâ€™t selected a licence yet, you might choose one â€“ e.g., MIT License. Then mention it here.)*

---

**Author**: Anagh  
**Repository**: https://github.com/anagh555i/NLP_sentence_analysis
